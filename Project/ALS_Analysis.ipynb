{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rNc25BxTSwtQ",
        "ezpoc-_wf5YJ",
        "8LpSWfrcgGHJ",
        "TlHjqPOmreLb",
        "IAWg8d4qS781",
        "_hycC8dtpFlD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Needed Library Import\n",
        "In this section the needed library to work with will be imported and some important variables will be initializatied"
      ],
      "metadata": {
        "id": "rNc25BxTSwtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZhWcP-oSuJm"
      },
      "outputs": [],
      "source": [
        "# In order to make the analysis reproducible\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDU1pSdXS3ok",
        "outputId": "fdd045e8-ed1b-4cb1-c04a-04ac744a4c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/681.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.4/681.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=5784d9a6afb78b7b648a3fd14557fb811acc303b7fedc6b6dd5b2c785982ec5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2Tn9uykXlYRjLcSLIgmv1iLdEvG_3gqA9M3V4hLGqH9N3JWEr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZw6mvj8TnnK",
        "outputId": "752215b3-570e-4caf-e0ca-a7c213a60dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Br58IkI_TrlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark Initialization\n",
        "In this section the connection with PySpark will be initializated"
      ],
      "metadata": {
        "id": "ezpoc-_wf5YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxrcGP2xTyZl",
        "outputId": "01a1608e-538f-48b5-e0fc-26368128842f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285388 sha256=6ce7c6f000bddf629328524bc0ccb139b39c9ecd7c740a8f2e601616be4dcd10\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as sqlf\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS, ALSModel\n",
        "from pyspark.mllib.evaluation import RankingMetrics"
      ],
      "metadata": {
        "id": "06Q4ABRZS3Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '4G').\\\n",
        "                set('spark.driver.memory', '45G').\\\n",
        "                set('spark.driver.maxResultSize', '10G').\\\n",
        "                setAppName(\"ALSAnalysis\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "pqjSANL6T6sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port = '4050'\n",
        "public_url = ngrok.connect(port).public_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJSFff4RT9by",
        "outputId": "d92c402b-65e6-4ffd-f67d-6c7ad4b498c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-17T09:44:12+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"To access the Spark Web UI console, please click on the following link to the ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kK75_JyT_n9",
        "outputId": "ccf6b7f7-1238-46eb-a5eb-45c7bd76695f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To access the Spark Web UI console, please click on the following link to the ngrok tunnel \"https://d158-34-105-119-107.ngrok-free.app\" -> \"http://127.0.0.1:4050\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "NuGJtC31UAQG",
        "outputId": "b55fbeae-6d04-49ee-d023-106331977442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7cf0e3739300>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f312b0052bf6:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>VideogameRecommenderSystem</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connection to Google Drive"
      ],
      "metadata": {
        "id": "8LpSWfrcgGHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect this colab to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PCbZ10zUFGE",
        "outputId": "2863840b-5ee0-4f63-de19-02cb38a4b69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "TlHjqPOmreLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score(predicted, actual, metric, k=None):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    predicted : List\n",
        "        List of predicted apps.\n",
        "    actual : List\n",
        "        List of masked apps.\n",
        "    metric : 'precision', 'recall', or 'ndcg'\n",
        "        A valid metric for recommendation.\n",
        "    k : int or None, optional\n",
        "        The value of k for precision and recall calculations. Default is None.\n",
        "    Raises\n",
        "    -----\n",
        "    Returns\n",
        "    -------\n",
        "    m : float\n",
        "        score.\n",
        "    \"\"\"\n",
        "    valid_metrics = ['precision', 'recall', 'ndcg']\n",
        "    if metric not in valid_metrics:\n",
        "        raise Exception(f\"Choose one valid baseline in the list: {valid_metrics}\")\n",
        "\n",
        "    if metric == 'precision':\n",
        "        if k is None:\n",
        "          m = np.mean([float(len(set(predicted[:k]) & set(actual))) / float(k)\n",
        "                     for k in range(1, len(predicted) + 1)])\n",
        "        else:\n",
        "          m = np.mean([float(len(set(predicted[:k]) & set(actual))) / float(k)])\n",
        "    elif metric == 'recall':\n",
        "        if k is None:\n",
        "            raise ValueError(\"Parameter 'k' must be specified for recall calculation.\")\n",
        "        m = np.mean([float(len(set(predicted[:k]) & set(actual))) / float(len(actual))])\n",
        "    elif metric == 'ndcg':\n",
        "        v = [1 if i in actual else 0 for i in predicted]\n",
        "        v_2 = [1 for i in actual]\n",
        "        dcg = sum([(2**i-1)/math.log(k+2, 2) for (k, i) in enumerate(v)])\n",
        "        idcg = sum([(2**i-1)/math.log(k+2, 2) for (k, i) in enumerate(v_2)])\n",
        "        m = dcg/idcg\n",
        "\n",
        "    return m\n"
      ],
      "metadata": {
        "id": "MHxyITK7Un0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALS analysis\n",
        "In the following section an analysis about the ALS model trained in *Videogame_Recommender_System.ipynb* will be performed.\n",
        "\n",
        "Specifically the **RMSE** will be computed together with other useful metrics about the performance of the Recommender System like **MAP** (Mean Average Precision), **Average NDCG** (Average Normalized Discounted Cumulative Gain), **Precision@K** and **Recall@K**"
      ],
      "metadata": {
        "id": "IAWg8d4qS781"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-traianed model\n",
        "als_model = ALSModel.load('/content/gdrive/MyDrive/VideogameRecommenderSystem/models/ALS11_08_2023__11_12_50')"
      ],
      "metadata": {
        "id": "zihhIJx-S7EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data about the users' activity\n",
        "user_activity_df = spark.read.load('/content/gdrive/MyDrive/VideogameRecommenderSystem/user_activity',\n",
        "                           format=\"csv\",\n",
        "                           sep=\",\",\n",
        "                           inferSchema=\"true\",\n",
        "                           header=\"true\")"
      ],
      "metadata": {
        "id": "AGMwhWs3brVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect some row samples\n",
        "user_activity_df.show(n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0-jHuscb0nq",
        "outputId": "9ad21e3f-3e47-4969-b807-2edd11bc6cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------+---------------+------+------------+\n",
            "|         steam_id|steam_appid|    recommended|rating|steam_int_id|\n",
            "+-----------------+-----------+---------------+------+------------+\n",
            "|76561198259233672|     951650|    Recommended|   3.0|           0|\n",
            "|76561198341423566|    1581451|    Recommended|   3.0|           1|\n",
            "|76561198031569409|       2310|    Recommended|   3.5|           2|\n",
            "|76561198031569409|     337000|    Recommended|   5.0|           2|\n",
            "|76561198031569409|    1353270|Not Recommended|   2.0|           2|\n",
            "+-----------------+-----------+---------------+------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like in the model training it is necessary to divide the dataset in training and test set, in order to have the same RMSE computed during the training the same seed, stored in RANDOM_SEED, will be used"
      ],
      "metadata": {
        "id": "s4Sh7V5YpkwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training, test) = user_activity_df.randomSplit([0.8, 0.2], seed=RANDOM_SEED)"
      ],
      "metadata": {
        "id": "s2pJS3hVUGdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tables with the predictions computed over the unkown data of the test set will be computed and in this way the RMSE will be presented"
      ],
      "metadata": {
        "id": "JX0Q7qXSpwvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = als_model.transform(test)"
      ],
      "metadata": {
        "id": "G6xYiyklTD9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"rmse\",\n",
        "    labelCol=\"rating\",\n",
        "    predictionCol=\"prediction\"\n",
        ")"
      ],
      "metadata": {
        "id": "NbDd6UDIcRVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the model do not perform very well, since the RMSE is 1 and a good value to be expected is at most 0.85"
      ],
      "metadata": {
        "id": "kozX3A9_p6wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NELJBiOqTM9Q",
        "outputId": "cc2962fb-cfd5-4feb-b209-e36ce497746f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 1.0652216001618737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two ways to compute recommendations with the model:\n",
        "\n",
        "1.   **recommendForUserSubset**: with this function it is needed to provide a subset of users on which compute the recommendation\n",
        "2.   **recommendForAllUsers**: with this function the recommendations are computed for all the users\n",
        "\n",
        "It is important to notice that in both cases it is necessary to explicitly say how many recommendations must be computed\n",
        "\n"
      ],
      "metadata": {
        "id": "7lToBY0UqVSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a subset with a single user\n",
        "user = spark.createDataFrame([168492], \"int\").toDF(\"steam_int_id\")"
      ],
      "metadata": {
        "id": "LatA1SoPTSAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the recommendation for the user\n",
        "steam_id = 168492\n",
        "user_recs = als_model.recommendForUserSubset(user, 5)\n",
        "print(f\"Top 5 recommendations for User {steam_id}:\")\n",
        "user_recs.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3K65EiDTTzJ",
        "outputId": "83e2f6c6-3820-4794-fb89-327a06782652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for User 168492:\n",
            "+------------+-------------------------------------------------------------------------------------------------------------+\n",
            "|steam_int_id|recommendations                                                                                              |\n",
            "+------------+-------------------------------------------------------------------------------------------------------------+\n",
            "|168492      |[{2184270, 4.9305077}, {1511610, 4.8229003}, {1262920, 4.803187}, {1304290, 4.6724615}, {1263100, 4.6717854}]|\n",
            "+------------+-------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate top-k recommendations for each user\n",
        "userRecs = als_model.recommendForAllUsers(5)  # Top-5 recommendations for each user\n",
        "\n",
        "# Prepare the input for RankingMetrics\n",
        "user_ground_truth = test.groupby('steam_int_id').agg(sqlf.collect_list('steam_appid').alias('ground_truth_items'))\n",
        "user_train_items = training.groupby('steam_int_id').agg(sqlf.collect_list('steam_appid').alias('train_items'))\n",
        "\n",
        "# Join the recommendations and ground truth data on the user ID\n",
        "user_eval = userRecs.join(user_ground_truth, on='steam_int_id').join(user_train_items, on='steam_int_id') \\\n",
        "    .select('steam_int_id', 'recommendations.steam_appid', 'ground_truth_items', 'train_items', 'recommendations.rating')\n",
        "user_eval = user_eval.toPandas()"
      ],
      "metadata": {
        "id": "249VEkrXTgu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_eval['itemIndex_filtered'] = user_eval.apply(lambda x:[b for (b,z) in zip(x.steam_appid, x.rating) if b not in x.train_items], axis=1)\n",
        "user_eval['rating_filtered'] = user_eval.apply(lambda x:[z for (b,z) in zip(x.steam_appid, x.rating) if b not in x.train_items], axis=1)"
      ],
      "metadata": {
        "id": "I-kONBedUght"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_eval['precision'] = user_eval.apply(lambda x: score(x.itemIndex_filtered, x.ground_truth_items, 'precision'), axis=1)\n",
        "user_eval['NDCG'] = user_eval.apply(lambda x: score(x.itemIndex_filtered, x.ground_truth_items, 'ndcg'), axis=1)"
      ],
      "metadata": {
        "id": "V29zA0ZwUqkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_eval['recall'] = user_eval.apply(lambda x: score(x.itemIndex_filtered, x.ground_truth_items, 'recall', 5), axis=1)\n",
        "user_eval['precisionAt'] = user_eval.apply(lambda x: score(x.itemIndex_filtered, x.ground_truth_items, 'precision', 5), axis=1)"
      ],
      "metadata": {
        "id": "mGydWGkJZRy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_eval.head()"
      ],
      "metadata": {
        "id": "H77rsli8UsvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAP = user_eval.precision.mean()\n",
        "avg_NDCG = user_eval.NDCG.mean()\n",
        "recall = user_eval.recall.mean()\n",
        "precision = user_eval.precisionAt.mean()"
      ],
      "metadata": {
        "id": "0vFU_nOmUtPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjkz4pYQUvql",
        "outputId": "1b343a7d-4699-4a6d-9a40-6d9332902ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.97416998027996e-06"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_NDCG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TO5LORYUxqz",
        "outputId": "3e345537-1da5-415f-d46e-abd24d20a46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.955919648603833e-06"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQnd2pFQZbFj",
        "outputId": "6314bcb7-0b75-47ad-8686-69d1dabd3f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.892486526178699e-06"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weZji23wZcf0",
        "outputId": "98253473-5f8c-4efe-f37e-2563e16d5283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9396760740956263e-06"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the data for the Demo"
      ],
      "metadata": {
        "id": "_hycC8dtpFlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_20_distinct_values = user_activity_df.groupBy('steam_id').count().orderBy(sqlf.col(\"count\").desc()).limit(20)"
      ],
      "metadata": {
        "id": "L68034PgxXFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_df = user_activity_df.join(top_20_distinct_values, on='steam_id', how=\"inner\")"
      ],
      "metadata": {
        "id": "CnXPwFlSxoSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_df = demo_df.drop(\"count\")"
      ],
      "metadata": {
        "id": "Bxn1xs-Uxu0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_df.write.options(header='True', delimiter=',').csv('/content/gdrive/MyDrive/VideogameRecommenderSystem/demo_data')"
      ],
      "metadata": {
        "id": "e013k5NUyJ7Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}